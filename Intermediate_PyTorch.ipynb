{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8LjEzf1SYOJwy9f/ZvIk8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fatma-Chaouech/PyTorch-Learning-Journey/blob/main/Intermediate_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "SESoXhvUq3PU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "oWT0o-6HsvkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, if a torch method ends with an underscore, it means that it directly affects the value of the passed variable, like inplace=True.\n",
        "\n",
        "We could also specify a variable that will contain the resulting value using the argument \"out\". The variable specified in \"out\" will be the exact same object as the variable that we affected the result to. Let's see a quick example :"
      ],
      "metadata": {
        "id": "4SSLRPMupaKx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOwIXha9otlH",
        "outputId": "91786419-c754-4830-a49f-5c39f0c0f6fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0.2058, 0.1343],\n",
            "        [1.1684, 1.1062]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.rand(2, 2)\n",
        "b = torch.rand(2, 2)\n",
        "c = torch.zeros(2, 2)\n",
        "old_id = id(c)\n",
        "\n",
        "print(c)\n",
        "d = torch.matmul(a, b, out=c)\n",
        "print(c)                # contents of c have changed\n",
        "\n",
        "assert c is d           # test c & d are same object, not just containing equal values\n",
        "assert id(c), old_id    # make sure that our new c is the same object as the old one"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable assigning in PyTorch doesn't generate a copy. If you want a separate copy of the data to work on, you should use the clone() method. "
      ],
      "metadata": {
        "id": "OjDqQdGGq9_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple assigning\n",
        "v = torch.ones(2, 2)\n",
        "u = v\n",
        "\n",
        "v[0][1] = 561  # we change a...\n",
        "print(v)       # ...and b is also altered\n",
        "\n",
        "\n",
        "# using clone()\n",
        "a = torch.ones(2, 2)\n",
        "b = a.clone()\n",
        "\n",
        "assert b is not a      # different objects in memory...\n",
        "print(torch.eq(a, b))  # ...but still with the same contents!\n",
        "\n",
        "a[0][1] = 561          # a changes...\n",
        "print(b)               # ...but b is still all ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXob9W-Sqo_E",
        "outputId": "9ee0f37f-7e47-47a5-e83a-9f56ba7d62ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1., 561.],\n",
            "        [  1.,   1.]])\n",
            "tensor([[True, True],\n",
            "        [True, True]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It's important to note that if your source tensor has autograd, enabled then so will the clone.** If you want to turn off the autograd, use the detach() method before cloning."
      ],
      "metadata": {
        "id": "UlRBjZlhsQz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Computing"
      ],
      "metadata": {
        "id": "I1dFVMqsszYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first need to check if we have a GPU available with .is_available() method."
      ],
      "metadata": {
        "id": "vsoqAOsatLDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('We have a GPU!')\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDEAkbDQro-1",
        "outputId": "eb4a9d46-86d0-468a-b0d2-98c2cdda1600"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have a GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CPU does computation on data in the computer's RAM. However, **the GPU has dedicated memory attached to it.** Thus, we should move all the data needed for that computation to memory accessible by the GPU. We often say that we \"move the data to the GPU\"."
      ],
      "metadata": {
        "id": "noEyfIm7ttaf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPdL4IF-tS_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}